{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pymysql \n",
    "import pymysql.cursors\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_update = {}\n",
    "insert_column = ()\n",
    "update_column = [] \n",
    "\n",
    "ssh_host = '3.36.21.112'\n",
    "ssh_port = '21'\n",
    "conn_resource = pymysql.connect(host='3.36.21.112', user='root', password='ckUdC17yqltr', db='resource')\n",
    "conn_testserver = pymysql.connect(host='3.36.21.112', user='root', password='ckUdC17yqltr', db='saladpet')\n",
    "\n",
    "cursor_resource = conn_resource.cursor() #dictionary 형태로 결과 반환 원해 -> pymysql.cursors.Dictcursor을 ()에 넣어줌.\n",
    "cursor_testserver = conn_testserver.cursor()\n",
    "\n",
    "## df_to_sql_resource 함수 : dataframe 형태를 sql에 upsert 할 수 있게 해줌 (단, 칼럼명이 sql의 칼럼명과 동일해야 함!)\n",
    "def df_to_sql_resource (df, table_name, primary_key) : # df = 넣을 dataframe, table_name = sql 테이블 이름, column = df와 동일한 순서의 칼럼, primary_key = PK or unique key로 on duplicate key 시에 사용하지 않는 것\n",
    "    column = df.columns.values.tolist()\n",
    "    insert_column = tuple(column)\n",
    "    update_column = column \n",
    "    for i in range (0,len(primary_key)):\n",
    "        update_column.remove(primary_key[i])\n",
    "    update_column = tuple(update_column)\n",
    "\n",
    "    word_1 = \"insert into %s (\" %table_name \n",
    "    word_2 = \"on duplicate key update\" \n",
    "\n",
    "    for l in range(0,len(update_column)):\n",
    "        if l < len(update_column)-1 :\n",
    "            word_2 = word_2 + \" \"+ update_column[l] + \" = %s,\"\n",
    "        if l == len(update_column)-1 :\n",
    "            word_2 = word_2 + \" \" + update_column[l] + \" = %s\"\n",
    "\n",
    "    for s in range(0,len(insert_column)):\n",
    "        if s < len(insert_column)-1 :\n",
    "            word_1 = word_1 + \" \"+ insert_column[s] + \",\"\n",
    "        if s == len(insert_column)-1 :\n",
    "            word_1 = word_1 + \" \"+ insert_column[s] + \" ) \"\n",
    "    word_1 = word_1 + \"VALUES (\" + \"%s,\"*(len(insert_column)-1) + \"%s)\"\n",
    "    print (word_1 + word_2)\n",
    "\n",
    "    for i in range (0,len(df)) :\n",
    "        a = df.iloc[i] # index = i 인 df를 series로 변환 \n",
    "        insert_data = a.to_dict() # series를 사전 형태로 변환 - insert 사전 목록 \n",
    "        update_data = a.to_dict() \n",
    "        for key in primary_key:\n",
    "            if key in update_data:\n",
    "                del update_data[key] # series를 사전 형태로 변환 - update 사전 목록 \n",
    "        data = list(insert_data.values()) + list(update_data.values()) #insert+update 목록 리스트 \n",
    "        sql = word_1 + word_2\n",
    "        cursor_resource.execute(sql,data)\n",
    "        conn_resource.commit()\n",
    "        i = i+1\n",
    "    print (\"finish insert %s\" %table_name )\n",
    "    print (\"넣은 row 수 총 %s 개\" %i ) \n",
    "    conn_resource.close()\n",
    "\n",
    "\n",
    "def df_to_sql_testserver (df, table_name, primary_key) : # df = 넣을 dataframe, table_name = sql 테이블 이름, column = df와 동일한 순서의 칼럼, primary_key = PK or unique key로 on duplicate key 시에 사용하지 않는 것\n",
    "    column = df.columns.values.tolist()\n",
    "    insert_column = tuple(column)\n",
    "    update_column = column \n",
    "    for i in range (0,len(primary_key)):\n",
    "        update_column.remove(primary_key[i])\n",
    "    update_column = tuple(update_column)\n",
    "\n",
    "    word_1 = \"insert into %s (\" %table_name \n",
    "    word_2 = \"on duplicate key update\" \n",
    "\n",
    "    for l in range(0,len(update_column)):\n",
    "        if l < len(update_column)-1 :\n",
    "            word_2 = word_2 + \" \"+ update_column[l] + \" = %s,\"\n",
    "        if l == len(update_column)-1 :\n",
    "            word_2 = word_2 + \" \" + update_column[l] + \" = %s\"\n",
    "\n",
    "    for s in range(0,len(insert_column)):\n",
    "        if s < len(insert_column)-1 :\n",
    "            word_1 = word_1 + \" \"+ insert_column[s] + \",\"\n",
    "        if s == len(insert_column)-1 :\n",
    "            word_1 = word_1 + \" \"+ insert_column[s] + \" ) \"\n",
    "    word_1 = word_1 + \"VALUES (\" + \"%s,\"*(len(insert_column)-1) + \"%s)\"\n",
    "    print (word_1 + word_2)\n",
    "\n",
    "    for i in range (0,len(df)) :\n",
    "        a = df.iloc[i] # index = i 인 df를 series로 변환 \n",
    "        insert_data = a.to_dict() # series를 사전 형태로 변환 - insert 사전 목록 \n",
    "        update_data = a.to_dict() \n",
    "        for key in primary_key:\n",
    "            if key in update_data:\n",
    "                del update_data[key] # series를 사전 형태로 변환 - update 사전 목록 \n",
    "        data = list(insert_data.values()) + list(update_data.values()) #insert+update 목록 리스트 \n",
    "        sql = word_1 + word_2\n",
    "        cursor_testserver.execute(sql,data)\n",
    "        conn_testserver.commit()\n",
    "        i = i+1\n",
    "    print (\"finish insert %s\" %table_name )\n",
    "    print (\"넣은 row 수 총 %s 개\" %i ) \n",
    "    conn_testserver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>ingred_row</th>\n",
       "      <th>ingred_name</th>\n",
       "      <th>function_ingredient_id</th>\n",
       "      <th>ingred_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13087</td>\n",
       "      <td>1</td>\n",
       "      <td>플루란</td>\n",
       "      <td>None</td>\n",
       "      <td>15115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13087</td>\n",
       "      <td>2</td>\n",
       "      <td>스피루리나</td>\n",
       "      <td>None</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13087</td>\n",
       "      <td>3</td>\n",
       "      <td>글리세린</td>\n",
       "      <td>None</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13087</td>\n",
       "      <td>4</td>\n",
       "      <td>합성착향료(블루베리향)</td>\n",
       "      <td>None</td>\n",
       "      <td>15117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13087</td>\n",
       "      <td>5</td>\n",
       "      <td>프로폴리스추출물</td>\n",
       "      <td>None</td>\n",
       "      <td>11798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product  ingred_row   ingred_name function_ingredient_id  ingred_index\n",
       "0    13087           1           플루란                   None         15115\n",
       "1    13087           2         스피루리나                   None          3585\n",
       "2    13087           3          글리세린                   None           792\n",
       "3    13087           4  합성착향료(블루베리향)                   None         15117\n",
       "4    13087           5      프로폴리스추출물                   None         11798"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# 1. 필요한 pandas, pymysql 셋팅 작업 #################\n",
    "import pandas as pd \n",
    "import pymysql \n",
    "import pymysql.cursors\n",
    "\n",
    "\n",
    "#######TEST_SERVER\n",
    "ssh_host = '3.36.21.112'\n",
    "ssh_port = '22'\n",
    "conn_resource = pymysql.connect(host='3.36.21.112', user='root', password='ckUdC17yqltr', db='resource')\n",
    "conn_testserver = pymysql.connect(host='3.36.21.112', user='root', password='ckUdC17yqltr', db='saladpet')\n",
    "\n",
    "\n",
    "#######SERVER\n",
    "# ssh_host = '15.165.92.95'\n",
    "# ssh_port = '12200'\n",
    "# conn_resource = pymysql.connect(host='15.165.92.95', user='root', password='COLCTveCNfY8', db= 'resource')\n",
    "# conn_testserver = pymysql.connect(host='15.165.92.95', user='root', password='COLCTveCNfY8', db='saladpet')\n",
    "\n",
    "#################################################################################################\n",
    "################## 2. 엑셀 전처리 시 필요한 SQL DB 불러오기 작업 ##################\n",
    "\n",
    "cursor_resource = conn_resource.cursor() #dictionary 형태로 결과 반환 원해 -> pymysql.cursors.Dictcursor을 ()에 넣어줌.\n",
    "sql_supplement_type = \"select * from supplement_type\"\n",
    "sql_map_product_cate = \"select * from map_product_cate\"\n",
    "\n",
    "supplement_type = pd.read_sql(sql_supplement_type, conn_resource) # 열이 포함된 형태로 select하려면 이 문자형태로 진행 \n",
    "map_product_cate = pd.read_sql(sql_map_product_cate, conn_resource)\n",
    "conn_resource.commit\n",
    "\n",
    "#supplement_type.set_index(\"type_id\", inplace = True ) # inplace = true는 변경 사항을 그대로 객체에 다시 저장한다.\n",
    "#map_product_cate.set_index(\"mc_pk\", inplace = True) \n",
    "\n",
    "\n",
    "\n",
    "################## 3. 엑셀 불러오기 작업 ####################\n",
    "excel_path = \"0906_supplement.xlsx\"\n",
    "df_pro = pd.read_excel( excel_path , sheet_name = \"product\",usecols= [0,1,2,3,4,5,6,7,8,9,10,11,12]) \n",
    "df_nu = pd.read_excel( excel_path , sheet_name = \"nutrient\",usecols = [0,1,2,3,4,5,6,7])\n",
    "df_cal = pd.read_excel(excel_path, sheet_name = \"calorie\")\n",
    "#df_fun = pd.read_excel(excel_path, sheet_name = \"function_ingredient\")\n",
    "df_price = pd.read_excel( excel_path, sheet_name = \"price\", usecols = [0,1,2,3,4,5,6])\n",
    "df_ingredient = pd.read_excel( excel_path, sheet_name = \"ingredient\")\n",
    "\n",
    "df_price['gift_unit'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "################ 4. 데이터 전처리 작업 ####################\n",
    "\n",
    "\n",
    "####### 문자를 숫자로 1.subtype_nm >> subtype_id 2. category(mc_nm) >> mc_pk\n",
    "df_pro = pd.merge(df_pro, supplement_type, how = 'left', left_on = 'subtype_nm', right_on = 'type_nm')\n",
    "df_pro = pd.merge(df_pro, map_product_cate, how = 'left', left_on = 'category', right_on = 'mc_nm')\n",
    "df_pro[\"lc_pk\"] = 3\n",
    "#product = df_pro.iloc[:,[0,1,2,5,6,7,8,9]]\n",
    "\n",
    "product = df_pro.loc [ : , ('product', 'prod_nm', 'brand_pk', 'salary_age', 'salary_type', 'pet_type', 'exp_type', 'exp_month') ]\n",
    "#supplement_unit = df_pro.iloc[:,[0,8,9,10,11]]\n",
    "\n",
    "supplement_unit = df_pro.loc [ : , ('product', 'least_unit', 'least_weight_unit', 'weight_unit', 'subtype_id')]\n",
    "product_cate = df_pro.loc[ :, ('product', 'lc_pk', 'mc_pk')]\n",
    "#product_cate = df_pro.iloc[:,[0,13,15]]\n",
    "\n",
    "\n",
    "\n",
    "######## nan >> none(null)\n",
    "\n",
    "# product = product.where(product.notnull(),None)\n",
    "# supplement_unit = supplement_unit.where(supplement_unit.notnull(),None)\n",
    "# df_price = df_price.where(df_price.notnull(),None)\n",
    "# df_nu = df_nu.where(df_nu.notnull(),None)\n",
    "# df_cal = df_cal.where(df_cal.notnull(),None)\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "#df_fun = df_fun.replace({np.nan:None})\n",
    "supplement_unit = supplement_unit.replace({np.nan: None})\n",
    "df_price = df_price.replace({np.nan: None})\n",
    "df_nu = df_nu.replace({np.nan: None})\n",
    "df_cal = df_cal.replace({np.nan: None})\n",
    "product = product.replace({np.nan: None})\n",
    "df_ingredient = df_ingredient.replace({np.nan: None})\n",
    "\n",
    "\n",
    "\n",
    "##################### 마지막 확인#################\n",
    "# product.info()\n",
    "# supplement_unit.info()\n",
    "# product_cate.info()\n",
    "# df_price.info()\n",
    "# df_nu.info()\n",
    "# df_cal.info()\n",
    "df_ingredient.head()\n",
    "\n",
    "#product.head()\n",
    "# supplement_unit.head()\n",
    "# product_cate.head()\n",
    "# df_price.head()\n",
    "# df_nu.head()\n",
    "# df_cal.head()\n",
    "# df_ingredient.head()\n",
    "\n",
    "#product.to_csv(\"products_mepet.csv\", index=False)\n",
    "#product.to_csv(\"products_mepet.csv\", index=False)\n",
    "# supplement_unit.to_csv(\"supplement_unit_mepet.csv\", index=False)\n",
    "# product_cate.to_csv(\"product_cate_mepet.csv\", index=False)\n",
    "# df_price.to_csv(\"search_price_detail_mepet.csv\", index=False)\n",
    "# df_nu.to_csv(\"product_nutrient_mepet.csv\", index=False)\n",
    "# df_cal.to_csv(\"product_calorie_mepet.csv\", index=False)\n",
    "# df_ingredient.to_csv(\"ingredient_mepet.csv\", index=False)\n",
    "\n",
    "\n",
    "##################### 집어넣기 (supplement_plan 제외)#############\n",
    "# p_table_name = \"products\" \n",
    "# p_pk = [\"product\"] \n",
    "\n",
    "# unit_table_name = \"supplement_unit\"\n",
    "# unit_pk = [\"product\"]\n",
    "\n",
    "# cate_table_name = \"product_cate\"\n",
    "# cate_pk = [\"product\"]\n",
    "\n",
    "\n",
    "# price_table_name = \"search_price_detail\"\n",
    "# price_pk = [\"product\"]\n",
    "\n",
    "# nu_table_name = \"product_nutrient\"\n",
    "# nu_pk = [\"product\"]\n",
    "\n",
    "# cal_table_name = \"product_calorie\"\n",
    "# cal_pk = [\"product\"]\n",
    "\n",
    "# ing_table_name = \"ingredient\"\n",
    "# ing_pk = [\"product\", \"ingred_row\"]\n",
    "\n",
    "# df_to_sql_resource(product, p_table_name , p_pk )\n",
    "# df_to_sql_resource(supplement_unit, unit_table_name , unit_pk)\n",
    "# df_to_sql_resource(product_cate, cate_table_name, cate_pk )\n",
    "# df_to_sql_resource(df_price, price_table_name, price_pk )\n",
    "# df_to_sql_resource(df_nu, nu_table_name, nu_pk)\n",
    "# df_to_sql_resource(df_cal, cal_table_name, cal_pk )\n",
    "# df_to_sql_resource(df_ingredient, ing_table_name, ing_pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_17720/1511572921.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\지상민\\AppData\\Local\\Temp/ipykernel_17720/1511572921.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    remote_bind_address=(127.0.0.1, 3306))\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "############################################### 새로운 시도###########################\n",
    "import pymysql\n",
    "import paramiko\n",
    "import pandas as pd\n",
    "from paramiko import SSHClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from os.path import expanduser\n",
    "\n",
    "home = expanduser('~')\n",
    "mypkey = paramiko.RSAKey.from_private_key_file(\"C:\\Users\\지상민\\Downloads\\LightsailDefaultKey-ap-northeast-2 (4).pem\")\n",
    "# if you want to use ssh password use - ssh_password='your ssh password', bellow\n",
    "\n",
    "sql_hostname = 'bitnami'\n",
    "sql_username = 'root'\n",
    "sql_password = 'COLCTveCNfY8'\n",
    "sql_main_database = 'db_name'\n",
    "sql_port = 3306\n",
    "ssh_host = 'ssh_hostname'\n",
    "ssh_user = 'ssh_username'\n",
    "ssh_port = 22\n",
    "sql_ip = '1.1.1.1.1'\n",
    "\n",
    "with SSHTunnelForwarder(\n",
    "        (ssh_host, ssh_port),\n",
    "        ssh_username=ssh_user,\n",
    "        ssh_pkey=mypkey,\n",
    "        remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "    conn = pymysql.connect(host='127.0.0.1', user=sql_username,\n",
    "            passwd=sql_password, db=sql_main_database,\n",
    "            port=tunnel.local_bind_port)\n",
    "    query = '''SELECT VERSION();'''\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### supplement plan 작업 \n",
    "import pandas as pd\n",
    "from numpy import nan as NA\n",
    "\n",
    "excel_path = \"0906_supplement.xlsx\"\n",
    "\n",
    "df_plan = pd.read_excel( excel_path, sheet_name = \"supplement_plan\")\n",
    "\n",
    "df_plan = df_plan.replace({np.nan: None})\n",
    "#df_plan = df_plan.where(df_plan.notnull(),None)  ## sql 에서는 모든 결측치 종류 중 none 만 null 로 판단함\n",
    "\n",
    "cond_1 = (df_plan['attribute'].isnull())\n",
    "\n",
    "df_plan.loc[cond_1, \"attribute\" ]  =  \"일반적인 경우\"\n",
    "\n",
    "cond_2 = (df_plan['pet_weight_min'] == 0)   \n",
    "\n",
    "df_plan.loc[ (df_plan['weight_unit'].isnull()) , 'pet_weight_min' ] = 0 \n",
    "df_plan.loc[ (df_plan['weight_unit'].isnull()) , 'weight_unit' ] = \"kg\"\n",
    "df_plan.loc[ (df_plan['pet_weight_min'].isnull()), 'pet_weight_min'] = 0  # 시작이 null인 데이터는, 0으로 셋팅해줘야 함 \n",
    "\n",
    "\n",
    "df_plan_group = df_plan.groupby(['product','attribute','pet_type']) # 연속 데이터 처리 작업 1\n",
    "index = df_plan_group.groups\n",
    "#{(12841, '일반적인 경우', 1): [4, 5, 6], (12842, '일반적인 경우', 1): [7, 8, 9]} 이런식으로 되어있음 (dict 형태로)\n",
    "\n",
    "\n",
    "for i in range (0, len(index)): \n",
    "\n",
    "    pk = list(index.values())[i] # index를 담는 list = pk로 정의, index.values() 는 dict 형태에서 : 오른쪽 꺼를 의미\n",
    "    df_group = (df_plan.iloc[pk, : ]) # df_plan 중 해당 index를 가진 row를 df화 시킴 \n",
    "    df_group = df_group.to_numpy().tolist() # df를 list화 시킴 \n",
    "\n",
    "    #지금 df_group은 아래 두줄과 같이 되어있음\n",
    "    #[[12841, '일반적인 경우', 1, 0.0, 5.0, 'kg', 1, 1.0, 1.0, 1, nan], [12841, '일반적인 경우', 1, 5.0, 10.0, 'kg', 1, 2.0, 2.0, 1, nan], [12841, '일반적인 경우', 1, 10.0, nan, 'kg', 1, 3.0, 3.0, 1, nan]]\n",
    "    #[[12842, '일반적인 경우', 1, 0.0, 5.0, 'kg', 1, 1.0, 1.0, 1, nan], [12842, '일반적인 경우', 1, 5.0, 10.0, 'kg', 1, 2.0, 2.0, 1, nan], [12842, '일반적인 경우', 1, 10.0, nan, 'kg', 1, 3.0, 3.0, 1, nan]]\n",
    "    \n",
    "    \n",
    "    if i == 0 :\n",
    "        groups = [df_group]\n",
    "\n",
    "    else :\n",
    "\n",
    "        groups += [df_group] # group box에 추가함 \n",
    "        groups\n",
    "\n",
    "result = []     # 추가해야할 데이터 리스트\n",
    "\n",
    "for group in groups:\n",
    "    init_min, init_max = group[0][3], group[0][4]                    # 그룹 첫번째 row의 min, max 값\n",
    "    prev_min, prev_max = init_min, init_max                          # 이전 min, max 값을 저장하는 변수 초기화\n",
    "\n",
    "    if len(group) >= 2:     # 그룹에 row가 2개 이상 일 때\n",
    "        \n",
    "        for i, row in enumerate(group): # 1. 중간 데이터들에 대해서 연속성 추가 작업// i(앞에꺼)는 인덱스, ROW(뒤에꺼) 는 진짜 값\n",
    "            if i == 0:                                               # row의 처음은 건너 뛰고 2번째 부터 비교\n",
    "                continue\n",
    "            cur_min, cur_max = row[3], row[4]                        # 현재 row의 min, max 값\n",
    "            if prev_max != cur_min:                                  # 이전 최대값과 현재 최소값이 같지 않을 경우\n",
    "                result.append( [group[i][0],group[i][1], group[i][2], prev_max, cur_min, group[i][5], group[i][6], group[i][7], group[i][8], group[i][9]] )\n",
    "            prev_min, prev_max = cur_min, cur_max                    # row를 비교 한 뒤 값 최신화\n",
    "\n",
    "        if group[0][3] != 0 :  # 2. 시작 데이터에 대해서 min이 0이 아닌 경우 추가 작업 \n",
    "            result.append([group[0][0], group[0][1], group[0][2], 0, init_min , group[0][5], group[0][6], group[0][7], group[0][8], group[0][9]])\n",
    "\n",
    "        if group[-1][4] is not None:      # 그룹의 마지막 row max 값이 Null 이 아닐 경우\n",
    "            result.append([group[-1][0], group[-1][1], group[-1][2], group[-1][4], None, group[-1][5], group[-1][6], group[-1][7], group[-1][8], group[-1][9] ])        # 최대값이 NULL 인 데이터 추가\n",
    "            \n",
    "    else:       # 그룹에 row가 1개 일 때 (그룹에 row가 무조건 1개 이상 있다는 가정 하에)\n",
    "        if group[0][3] != 0 and group[0][4] != None : \n",
    "            result.append([group[0][0], group[0][1], group[0][2], init_max, None, group[0][5], group[0][6], group[0][7], group[0][8], group[0][9]]) \n",
    "            result.append([group[0][0], group[0][1], group[0][2], 0, init_min , group[0][5], group[0][6], group[0][7], group[0][8], group[0][9]])\n",
    "        if group[0][3] == 0 and group[0][4] != None  : \n",
    "            result.append([group[0][0], group[0][1], group[0][2], init_max, None, group[0][5], group[0][6], group[0][7], group[0][8], group[0][9]])                 # 최대값이 NULL 인 데이터 추가\n",
    "            \n",
    "        if group[0][3] != 0 and group[0][4] == None  :\n",
    "            result.append([group[0][0], group[0][1], group[0][2], 0, init_min , group[0][5], group[0][6], group[0][7], group[0][8], group[0][9]]) # 최소값이 0이고, 최대가 init인 데이터 추가 \n",
    "\n",
    " \n",
    "column = ['product', 'attribute', 'pet_type', 'pet_weight_min', 'pet_weight_max','weight_unit', 'time_per_day', 'min_amount', 'max_amount', 'per_unit']\n",
    "\n",
    "df_plus = pd.DataFrame.from_records( result , columns = column )\n",
    "\n",
    "def func1(row):\n",
    "    if '~' in str(row) :\n",
    "        row_1 = row.split('~')[0]\n",
    "        row_2 = row.split('~')[1]\n",
    "    else :\n",
    "        row_1 = row\n",
    "        row_2 = row \n",
    "    return pd.Series([row_1, row_2])\n",
    "\n",
    "df_plan = pd.concat([df_plus, df_plan])\n",
    "\n",
    "df_plan[['time_per_day_min', 'time_per_day_max']] = df_plan['time_per_day'].apply(func1)\n",
    "\n",
    "df_plan['time_per_day_min']= df_plan['time_per_day_min'].astype(int)\n",
    "df_plan['time_per_day_max']= df_plan['time_per_day_max'].astype(int)\n",
    "df_plan = df_plan.drop(columns = 'time_per_day')\n",
    "\n",
    "con_3 = ( df_plan['pet_weight_max'].isnull() )\n",
    "\n",
    "df_plan.loc[con_3, 'pet_weight_max']  = 1000 \n",
    "\n",
    "\n",
    "df_plan.loc[ (df_plan['pet_weight_min'].isnull()), 'pet_weight_min' ] = 0\n",
    "\n",
    "\n",
    "##################### 확인 (0~1000 잘 되어있는지)\n",
    "df_plan.head(10)\n",
    "# <개수 확인> min의 0 개수 = max의 1000 개수 = product, attribute, pet_type 을 pk 로 잡았을때 중복제거 한 값 개수\n",
    "\n",
    "df_plan.to_csv(\"supplement_plan_mepet.csv\", index=False)\n",
    "### 집어넣기\n",
    "\n",
    "#df_plan_table = \"supplement_plan\"\n",
    "#df_plan_pk = [\"product\", \"attribute\", \"pet_type\", \"pet_weight_min\", \"pet_weight_max\"]\n",
    "#df_to_sql_resource (df_plan, df_plan_table, df_plan_pk )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf71a6bc6049b8bef4ba42f78bb92433b54a62d68f65b768e5c2169dc44a9df9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
