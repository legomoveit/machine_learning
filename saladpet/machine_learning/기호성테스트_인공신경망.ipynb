{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pymysql \n",
    "import pymysql.cursors\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, logit, glm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "#-------------------------------------\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#-------------------------------------\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#-------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#-------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "#-------------------------------------\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog1 = pd.read_excel(\"c:\\import\\gihosung\\dog1_test_result.xlsx\")\n",
    "# dog2 = pd.read_excel(\"c:\\import\\gihosung\\dog2_test_result.xlsx\")\n",
    "#cat_zero = pd.read_excel(\"c:\\import\\gihosung\\cat_zero_test_result.xlsx\")\n",
    "# cat_zero2 = pd.read_excel(\"c:\\import\\gihosung\\cat_zero2_test_result.xlsx\")\n",
    "cat_dongdong = pd.read_excel(\"c:\\import\\gihosung\\s_1_test_result\\cat_dongdong_test_result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat_dongdong\n",
    "\n",
    "x = df[['p_cow' , 'p_chicken' , 'p_fish' , 'p_turkey' , 'p_sheep' ,  'p_salmon' , 'p_tuna'  , 'o_chicken' , 'o_fish' , 'flavor']]\n",
    "y = df[['little_score']]\n",
    "feature_list = ['p_cow' , 'p_chicken' , 'p_fish' , 'p_turkey' , 'p_sheep' ,  'p_salmon' , 'p_tuna'  , 'o_chicken' , 'o_fish' , 'flavor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\visual studio\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\visual studio\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.909359415647156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = MLPRegressor(random_state=0,alpha =1,max_iter = 200, hidden_layer_sizes=[1,1])\n",
    "#random_state\n",
    "#alpha : 학습률, 모형의 복잡도를 규제하는 규제항 역할을 하며 기본값은 0.001 / 높이면 규제 강화되어 모형의 일반화 성능이 높아지나 필요이상으로 높이면 과소적합 문제 발생\n",
    "#max_iter : 모형이 최적화되는 최대 반복 횟수로 기본값은 200이다. 학습률이나 은닉층 설정과 마찬가지로 여러번의 실험을 통해 지정, 일반적으로 은닉층과 은닉노드가 많을수록 최대반복횟수를 크게 지정\n",
    "#hidden_layer_size : 은닉층과 은닉노드의 개수 , 최적의 은닉층 및 은닉노드 개수를 정하는 명확한 방법론 x, 대부분의 비즈니스 문제는 1\n",
    "\n",
    "model.fit(x,y)\n",
    "model.score(x,y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf71a6bc6049b8bef4ba42f78bb92433b54a62d68f65b768e5c2169dc44a9df9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
